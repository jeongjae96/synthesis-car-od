{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo\n",
    "#### reference : https://dacon.io/competitions/official/236107/codeshare/8414?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "MODEL = \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(data_path + \"yolo\"):\n",
    "#     shutil.rmtree(data_path + \"yolo\")\n",
    "\n",
    "if not os.path.exists(data_path + \"yolo/train\"):\n",
    "    os.makedirs(data_path + \"yolo/train\")\n",
    "    \n",
    "if not os.path.exists(data_path + \"yolo/valid\"):\n",
    "    os.makedirs(data_path + \"yolo/valid\")\n",
    "    \n",
    "if not os.path.exists(data_path + \"yolo/test\"):\n",
    "    os.makedirs(data_path + \"yolo/test\")    \n",
    "    \n",
    "if not os.path.exists(\"../../results\"):\n",
    "    os.makedirs(\"../../results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yolo_dataset(image_paths, txt_paths, type=\"train\"):\n",
    "    for image_path, txt_path in tqdm(zip(image_paths, txt_paths if not type == \"test\" else image_paths), total=len(image_paths)):\n",
    "        source_image = cv2.imread(image_path, cv2.IMREAD_COLOR)        \n",
    "        image_height, image_width, _ = source_image.shape\n",
    "        \n",
    "        target_image_path = f\"{data_path}yolo/{type}/{os.path.basename(image_path)}\"\n",
    "        cv2.imwrite(target_image_path, source_image)\n",
    "        \n",
    "        if type == \"test\":\n",
    "            continue\n",
    "        \n",
    "        with open(txt_path, \"r\") as reader:\n",
    "            yolo_labels = []\n",
    "            for line in reader.readlines():\n",
    "                line = list(map(float, line.strip().split(\" \")))\n",
    "                class_name = int(line[0])\n",
    "                x_min, y_min = float(min(line[5], line[7])), float(min(line[6], line[8]))\n",
    "                x_max, y_max = float(max(line[1], line[3])), float(max(line[2], line[4]))\n",
    "                x, y = float(((x_min + x_max) / 2) / image_width), float(((y_min + y_max) / 2) / image_height)\n",
    "                w, h = abs(x_max - x_min) / image_width, abs(y_max - y_min) / image_height\n",
    "                yolo_labels.append(f\"{class_name} {x} {y} {w} {h}\")\n",
    "            \n",
    "        target_label_txt = f\"{data_path}yolo/{type}/{os.path.basename(txt_path)}\"      \n",
    "        with open(target_label_txt, \"w\") as writer:\n",
    "            for yolo_label in yolo_labels:\n",
    "                writer.write(f\"{yolo_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(glob(data_path + \"train/*.png\"))\n",
    "txt_paths = sorted(glob(data_path + \"train/*.txt\"))\n",
    "\n",
    "train_images_paths, valid_images_paths, train_txt_paths, valid_txt_paths = train_test_split(image_paths, txt_paths, test_size=0.1, random_state=SEED)\n",
    "\n",
    "make_yolo_dataset(train_images_paths, train_txt_paths, \"train\")\n",
    "make_yolo_dataset(valid_images_paths, valid_txt_paths, \"valid\")\n",
    "make_yolo_dataset(sorted(glob(data_path + \"test/*.png\")), None, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"classes.txt\", \"r\") as reader:\n",
    "    lines = reader.readlines()\n",
    "    classes = [line.strip().split(\",\")[1] for line in lines]\n",
    "\n",
    "yaml_data = {\n",
    "              \"names\": classes,\n",
    "              \"nc\": len(classes),\n",
    "              \"path\": \"../../../data/yolo/\",\n",
    "              \"train\": \"train\",\n",
    "              \"val\": \"valid\",\n",
    "              \"test\": \"test\"\n",
    "            }\n",
    "\n",
    "with open(data_path + \"yolo/custom.yaml\", \"w\") as writer:\n",
    "    yaml.dump(yaml_data, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x\")\n",
    "results = model.train(\n",
    "    data= data_path + \"yolo/custom.yaml\",\n",
    "    imgsz=(1024, 1024),\n",
    "    epochs=200,\n",
    "    batch=BATCH_SIZE,\n",
    "    patience=5,\n",
    "    workers=16,\n",
    "    device=0,\n",
    "    exist_ok=True,    \n",
    "    project=f\"{MODEL}\",\n",
    "    name=\"train\",\n",
    "    seed=SEED,\n",
    "    pretrained=False,\n",
    "    resume=False, # 여기 변경?! True -> False\n",
    "    optimizer=\"Adam\",\n",
    "    lr0=1e-3,\n",
    "    augment=True,\n",
    "    val=True,\n",
    "    cache=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_image_paths(test_image_paths):    \n",
    "    for i in range(0, len(test_image_paths), BATCH_SIZE):\n",
    "        yield test_image_paths[i:i+BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"v2/train/weights/best.pt\")\n",
    "test_image_paths = glob(data_path + \"yolo/test/*.png\")\n",
    "for i, image in tqdm(enumerate(get_test_image_paths(test_image_paths)), total=int(len(test_image_paths)/BATCH_SIZE)):\n",
    "    model.predict(image, imgsz=(1024, 1024), iou=0.2, conf=0.5, save_conf=True, save=False, save_txt=True, project=f\"{MODEL}\", name=\"predict\",\n",
    "                  exist_ok=True, device=0, augment=True, verbose=False)\n",
    "    if i % 5 == 0:\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_labelme(line, image_width, image_height, txt_file_name):    \n",
    "    file_name = txt_file_name.split(\"/\")[-1].replace(\".txt\", \".png\")\n",
    "    class_id, x, y, width, height, confidence = [float(temp) for temp in line.split()]\n",
    "    \n",
    "    x_min = int((x - width / 2) * image_width)\n",
    "    x_max = int((x + width / 2) * image_width)\n",
    "    y_min = int((y - height / 2) * image_height)\n",
    "    y_max = int((y + height / 2) * image_height)\n",
    "    \n",
    "    return file_name, int(class_id), confidence, x_min, y_min, x_max, y_min, x_max, y_max, x_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_txts = glob(f\"{MODEL}/predict/labels/*.txt\")\n",
    "\n",
    "results = []\n",
    "for infer_txt in tqdm(infer_txts):\n",
    "    base_file_name = infer_txt.split(\"/\")[-1].split(\".\")[0]\n",
    "    imgage_height, imgage_width = cv2.imread(f\"{data_path}test/{base_file_name}.png\").shape[:2]        \n",
    "    with open(infer_txt, \"r\") as reader:        \n",
    "        lines = reader.readlines()        \n",
    "        for line in lines:\n",
    "            results.append(yolo_to_labelme(line, imgage_width, imgage_height, infer_txt))\n",
    "\n",
    "df_submission = pd.DataFrame(data=results, columns=[\"file_name\", \"class_id\", \"confidence\", \"point1_x\", \"point1_y\", \"point2_x\", \"point2_y\", \"point3_x\", \"point3_y\", \"point4_x\", \"point4_y\"])\n",
    "df_submission.to_csv(f\"../../results/{MODEL}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
